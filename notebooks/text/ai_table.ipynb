{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# AI_TABLE\n",
    "\n",
    "## Overview\n",
    "This function interacts with an AI model to generate structured table data (2D list) based on a prompt. It can optionally use a header (for column names) and/or source data (2D list) to guide the table generation. The function is compatible with OpenAI/Mistral-style APIs that support JSON output.\n",
    "\n",
    "## Usage\n",
    "To use the `AI_TABLE` function in Excel, enter it as a formula in a cell, specifying your prompt and any optional arguments as needed:\n",
    "\n",
    "```excel\n",
    "=AI_TABLE(prompt, [header], [source], [temperature], [max_tokens], [model], [api_key], [api_url])\n",
    "```\n",
    "Replace each parameter with your desired value. The function returns a 2D list (table) generated by the AI model.\n",
    "\n",
    "## Parameters\n",
    "| Parameter      | Type     | Required | Description                                                                                                 |\n",
    "|---------------|----------|----------|-------------------------------------------------------------------------------------------------------------|\n",
    "| prompt        | string   | Yes      | The instruction describing the table the AI should create.                                                  |\n",
    "| header        | 2D list  | No       | A single row list defining the exact column headers for the table. If not specified, the model generates its own headers. |\n",
    "| source        | 2D list  | No       | Source data provided to the AI to use as a basis for generating the table content.                          |\n",
    "| temperature   | float    | No       | Controls the randomness/creativity of the response (0.0 to 2.0). Lower values are more deterministic.       |\n",
    "| max_tokens    | int      | No       | Maximum number of tokens for the generated table content (5 to 5000).                                       |\n",
    "| model         | string   | No       | The specific AI model ID to use (must support JSON mode, e.g., 'mistral-small-latest').                     |\n",
    "| api_key       | string   | No       | API key for authentication. [Get a free API key from Mistral AI](https://console.mistral.ai/).              |\n",
    "| api_url       | string   | No       | OpenAI-compatible API endpoint URL (e.g., https://api.mistral.ai/v1/chat/completions).                      |\n",
    "\n",
    "## Return Value\n",
    "| Return Value | Type    | Description                                                                                                                               |\n",
    "|--------------|---------|-------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Table Data   | 2D list | A list of lists representing the generated table. The first row typically contains headers (unless provided via `header` argument). Returns `[ [\"Error: ...\"] ]` on failure. |\n",
    "\n",
    "## Demo\n",
    "If either `api_key` or `api_url` is not provided, both will default to Boardflare demo values (`api_url`: https://llm.boardflare.com, `api_key`: your Microsoft login token if available). This only works for users logged in with a Microsoft account and provides limited free demo usage. You may obtain a free api_key for [Mistral AI](https://console.mistral.ai/) with your Microsoft account which offers more generous free usage and supports CORS.\n",
    "\n",
    "## Limitations\n",
    "- The quality of the table depends on the clarity of the prompt and the data provided.\n",
    "- Large data ranges may exceed model context limits and result in truncated or incomplete tables.\n",
    "- The function requires an internet connection to access the AI model.\n",
    "- Model availability and output may vary depending on the provider or API changes.\n",
    "- Sensitive or confidential data should not be sent to external AI services.\n",
    "- `temperature` must be a float between 0 and 2 (inclusive). If not, a ValueError is raised.\n",
    "- `max_tokens` must be an integer between 5 and 5000 (inclusive). If not, a ValueError is raised.\n",
    "- If you hit the API rate limit for your provider, a message is returned instead of raising an exception.\n",
    "\n",
    "## Benefits\n",
    "- Automates table generation, summarization, and business reporting directly in Excel.\n",
    "- Saves time and improves consistency in reporting and analysis.\n",
    "- Enables dynamic, context-aware tables using your own data.\n",
    "- More flexible and powerful than manual or native Excel approaches for table generation and analysis.\n",
    "\n",
    "## Examples\n",
    "\n",
    "### Basic Table Generation\n",
    "Generate a simple table listing smartphone features.\n",
    "\n",
    "**Sample Formula:**\n",
    "```excel\n",
    "=AI_TABLE(\"Create a table listing the features of 4 different smartphones including brand, model, camera quality, battery life.\")\n",
    "```\n",
    "\n",
    "**Sample Output:**\n",
    "| Brand   | Model     | Camera Quality | Battery Life |\n",
    "|---------|-----------|----------------|--------------|\n",
    "| Apple   | iPhone 15 | Excellent      | Good         |\n",
    "| Samsung | Galaxy S24| Excellent      | Very Good    |\n",
    "| Google  | Pixel 8   | Very Good      | Good         |\n",
    "| OnePlus | 12        | Good           | Excellent    |\n",
    "\n",
    "### Using a Specific Header\n",
    "Generate a table of tourist destinations using a predefined header.\n",
    "\n",
    "**Sample Header Data (Range `A1:D1`):**\n",
    "| Country | Popular Attractions | Best Time to Visit | Average Cost |\n",
    "|---------|---------------------|--------------------|--------------|\n",
    "\n",
    "```excel\n",
    "=AI_TABLE(\"Generate a table of top 5 tourist destinations.\", A1:D1)\n",
    "```\n",
    "\n",
    "### Using Source Data\n",
    "Generate a table summarizing product sales based on provided source data.\n",
    "\n",
    "**Sample Input Data (Range `A1:C8`):**\n",
    "| Product  | Category | Sales Amount |\n",
    "|----------|----------|--------------|\n",
    "| Laptop   | Tech     | 1200         |\n",
    "| Mouse    | Tech     | 25           |\n",
    "| Keyboard | Tech     | 75           |\n",
    "| T-Shirt  | Apparel  | 20           |\n",
    "| Jeans    | Apparel  | 50           |\n",
    "| Laptop   | Tech     | 1350         |\n",
    "| Hoodie   | Apparel  | 45           |\n",
    "\n",
    "```excel\n",
    "=AI_TABLE(\"Summarize the sales data by product category.\", , A1:C8)\n",
    "```\n",
    "\n",
    "**Sample Output:**\n",
    "| Category | Total Sales | Number of Items |\n",
    "|----------|-------------|-----------------|\n",
    "| Tech     | 2650        | 4               |\n",
    "| Apparel  | 115         | 3               |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def ai_table(prompt, header=None, source=None, temperature=0.0, max_tokens=1500, model='mistral-small-latest', api_key=None, api_url=None):\n",
    "    \"\"\"\n",
    "    Uses AI to generate a structured table based on the prompt and optional header/source data.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): Instruction for AI to create a table\n",
    "        header (list, optional): 2D list containing table header (column names)\n",
    "        source (list, optional): 2D list containing source data used to create the table\n",
    "        temperature (float, optional): Controls response creativity (0-2). Default is 0.0\n",
    "        max_tokens (int, optional): Maximum tokens for response generation. Default is 1500\n",
    "        model (str, optional): ID of the model to use\n",
    "        api_key (str, optional): API key for authentication (e.g. for Mistral AI)\n",
    "        api_url (str, optional): OpenAI compatible URL. (e.g., https://api.mistral.ai/v1/chat/completions)\n",
    "\n",
    "    Returns:\n",
    "        list: 2D list representing the generated table data\n",
    "    \"\"\"\n",
    "    # Demo fallback: Boardflare\n",
    "    if api_key is None or api_url is None:\n",
    "        if 'idToken' in globals():\n",
    "            api_key = globals()['idToken']\n",
    "            api_url = \"https://llm.boardflare.com\"\n",
    "        else:\n",
    "            return \"Login on the Functions tab for limited demo usage, or sign up for a free Mistral AI account at https://console.mistral.ai/ and add your own api_key.\"\n",
    "\n",
    "    # Validate temperature\n",
    "    if not isinstance(temperature, (float, int)) or not (0 <= float(temperature) <= 2):\n",
    "        raise ValueError(\"temperature must be a float between 0 and 2 (inclusive)\")\n",
    "    # Validate max_tokens\n",
    "    if not isinstance(max_tokens, int) or not (5 <= max_tokens <= 5000):\n",
    "        raise ValueError(\"max_tokens must be an integer between 5 and 5000 (inclusive)\")\n",
    "\n",
    "    # Construct the message\n",
    "    table_prompt = f\"Generate a well-organized table based on this request: {prompt}\"\n",
    "    if header is not None and header and len(header) > 0:\n",
    "        header_str = \", \".join(str(col) for col in header[0])\n",
    "        table_prompt += f\"\\nUse exactly these columns: {header_str}\"\n",
    "    if source is not None:\n",
    "        source_str = json.dumps(source, indent=2)\n",
    "        table_prompt += f\"\\n\\nUse this source data to create the table:\\n{source_str}\"\n",
    "    table_prompt += (\"\\nReturn ONLY a JSON object with a key 'items' whose value is a JSON array of arrays (2D array) with the table data. \"\n",
    "                     \"The first row should contain column headers if not provided. \"\n",
    "                     \"Each subsequent row should contain data that fits the columns. \"\n",
    "                     \"Do not include any explanatory text, just the JSON object. \"\n",
    "                     \"For example: {\\\"items\\\": [[\\\"Header1\\\", \\\"Header2\\\"], [\\\"Row1Col1\\\", \\\"Row1Col2\\\"]]}\")\n",
    "\n",
    "    payload = {\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": table_prompt}],\n",
    "        \"temperature\": float(temperature),\n",
    "        \"model\": model,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"response_format\": {\"type\": \"json_object\"}\n",
    "    }\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Accept\": \"application/json\"\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(api_url, headers=headers, json=payload)\n",
    "        if response.status_code == 429:\n",
    "            return [[\"You have hit the rate limit for the API. Please try again later.\"]]\n",
    "        response.raise_for_status()\n",
    "        response_data = response.json()\n",
    "        # If the response does not have 'choices', treat as error\n",
    "        if not isinstance(response_data, dict) or 'choices' not in response_data:\n",
    "            # Try to extract a message from common error keys\n",
    "            err_msg = None\n",
    "            for k in ('error', 'message', 'detail'):  # common API error keys\n",
    "                if k in response_data:\n",
    "                    err_msg = response_data[k]\n",
    "                    break\n",
    "            if not err_msg:\n",
    "                err_msg = str(response_data)\n",
    "            return f\"Error: {err_msg}\"\n",
    "        content = response_data[\"choices\"][0][\"message\"][\"content\"]\n",
    "        try:\n",
    "            table_data = json.loads(content)\n",
    "            if isinstance(table_data, dict) and \"items\" in table_data:\n",
    "                table_data = table_data[\"items\"]\n",
    "            elif isinstance(table_data, dict):\n",
    "                for key in (\"data\", \"filled_data\", \"result\"):\n",
    "                    if key in table_data:\n",
    "                        table_data = table_data[key]\n",
    "                        break\n",
    "            if isinstance(table_data, list) and all(isinstance(row, list) for row in table_data):\n",
    "                return table_data\n",
    "            else:\n",
    "                return f\"Error: Unable to parse response. Expected a 2D array.\"\n",
    "        except (json.JSONDecodeError, ValueError):\n",
    "            return f\"Error: Unable to generate table. The AI response wasn't in the expected format.\"\n",
    "    except Exception as e:\n",
    "        msg = str(e)\n",
    "        return f\"Error: {msg}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q ipytest\n",
    "import ipytest\n",
    "ipytest.autoconfig()\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path().resolve().parent.parent / \"test\"))\n",
    "from test_utils import get_graph_token\n",
    "\n",
    "def inject_id_token():\n",
    "    # Acquire token using shared utility\n",
    "    token = get_graph_token()\n",
    "    globals()[\"idToken\"] = token\n",
    "\n",
    "inject_id_token()\n",
    "\n",
    "def test_smartphone_features():\n",
    "    prompt = \"Create a table listing the features of 4 different smartphones including brand, model, camera quality, battery life.\"\n",
    "    result = ai_table(prompt)\n",
    "    assert isinstance(result, list)\n",
    "    assert any(\"Brand\" in str(row) or \"Model\" in str(row) for row in result)\n",
    "    assert len(result) >= 2\n",
    "\n",
    "def test_tourist_destinations_with_header():\n",
    "    prompt = \"Generate a table of top 5 tourist destinations.\"\n",
    "    header = [[\"Country\", \"Popular Attractions\", \"Best Time to Visit\", \"Average Cost\"]]\n",
    "    result = ai_table(prompt, header=header)\n",
    "    assert isinstance(result, list)\n",
    "    assert any(\"Country\" in str(row) for row in result)\n",
    "    assert len(result) >= 2\n",
    "\n",
    "def test_sales_summary_with_source():\n",
    "    prompt = \"Summarize the sales data by product category (2 categories).\"\n",
    "    source = [\n",
    "        [\"Product\", \"Category\", \"Sales Amount\"],\n",
    "        [\"Laptop\", \"Tech\", 1200],\n",
    "        [\"Mouse\", \"Tech\", 25],\n",
    "        [\"Keyboard\", \"Tech\", 75],\n",
    "        [\"T-Shirt\", \"Apparel\", 20],\n",
    "        [\"Jeans\", \"Apparel\", 50],\n",
    "        [\"Laptop\", \"Tech\", 1350],\n",
    "        [\"Hoodie\", \"Apparel\", 45]\n",
    "    ]\n",
    "    result = ai_table(prompt, source=source)\n",
    "    assert isinstance(result, list)\n",
    "    assert any(\"Category\" in str(row) for row in result)\n",
    "    assert len(result) >= 2\n",
    "\n",
    "ipytest.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradio Demo\n",
    "import gradio as gr\n",
    "\n",
    "def run_ai_table(prompt, header, source, temperature, max_tokens, model):\n",
    "    return ai_table(prompt, header=header, source=source, temperature=temperature, max_tokens=max_tokens, model=model)\n",
    "\n",
    "examples = [\n",
    "    [\n",
    "        \"Create a table listing the features of 4 different smartphones including brand, model, camera quality, battery life.\",\n",
    "        None,\n",
    "        None,\n",
    "        0.0,\n",
    "        1500,\n",
    "        \"mistral-small-latest\"\n",
    "    ],\n",
    "    [\n",
    "        \"Generate a table of top 5 tourist destinations.\",\n",
    "        [[\"Country\", \"Popular Attractions\", \"Best Time to Visit\", \"Average Cost\"]],\n",
    "        None,\n",
    "        0.0,\n",
    "        1500,\n",
    "        \"mistral-small-latest\"\n",
    "    ],\n",
    "    [\n",
    "        \"Summarize the sales data by product category (2 categories).\",\n",
    "        None,\n",
    "        [\n",
    "            [\"Product\", \"Category\", \"Sales Amount\"],\n",
    "            [\"Laptop\", \"Tech\", 1200],\n",
    "            [\"Mouse\", \"Tech\", 25],\n",
    "            [\"Keyboard\", \"Tech\", 75],\n",
    "            [\"T-Shirt\", \"Apparel\", 20],\n",
    "            [\"Jeans\", \"Apparel\", 50],\n",
    "            [\"Laptop\", \"Tech\", 1350],\n",
    "            [\"Hoodie\", \"Apparel\", 45]\n",
    "        ],\n",
    "        0.0,\n",
    "        1500,\n",
    "        \"mistral-small-latest\"\n",
    "    ]\n",
    "]\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=ai_table,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"Prompt\", lines=2, value=\"Create a table listing the features of 4 different smartphones including brand, model, camera quality, battery life.\"),\n",
    "        gr.Dataframe(label=\"Header (optional)\", type=\"array\", headers=None, datatype=\"str\", row_count=(1, \"dynamic\"), col_count=(1, \"dynamic\")),\n",
    "        gr.Dataframe(label=\"Source Data (optional)\", type=\"array\", headers=None, datatype=\"str\", row_count=(1, \"dynamic\"), col_count=(1, \"dynamic\")),\n",
    "        gr.Slider(0.0, 2.0, value=0.0, step=0.01, label=\"Temperature\"),\n",
    "        gr.Number(value=1500, label=\"Max Tokens\"),\n",
    "        gr.Textbox(value=\"mistral-small-latest\", label=\"Model\")\n",
    "    ],\n",
    "    outputs=gr.Dataframe(label=\"AI Table Output\"),\n",
    "    examples=examples,\n",
    "    description=\"Interact with the AI Table function. Enter a prompt and, optionally, provide a header or source data for the AI to use. Adjust the temperature for creativity, set the maximum number of tokens for the response, and specify the model if desired.\",\n",
    "    flagging_mode=\"never\",\n",
    ")\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
